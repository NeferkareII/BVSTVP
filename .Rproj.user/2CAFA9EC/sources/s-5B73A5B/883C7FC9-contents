## Some code for doing regression "manually"
## Gregor Kastner 2017

## Define predictors and response

y <- c(95, 60, 80, 85, 50) # think of scores at some test

x1 <- c(2000, 500, 1500, 1700, 500) # think of minutes studies
x2 <- c(110, 100, 105, 100, 95) # think of IQ

n <- length(y)

## The usual way using lm:
mylm <- lm(y ~ x1 + x2)
summary(mylm)

## Using the formulas from the slides:
# Design matrix X:
X <- cbind(1, x1, x2)

# (X'X)^(-1)
tmp <- solve(t(X) %*% X)
tmp <- solve(crossprod(X)) # same thing but slightly faster

# (X'X)^(-1)X'y
betahat <- tmp %*% t(X) %*% y

# check for equality:
coef(mylm) 
betahat # same!

# predicted values:
yhat <- X %*% betahat

# check for equality:
predict(mylm)
yhat # yeah!

# residuals:
resids <- y - yhat 

# check for equality:
resid(mylm)
resids # nice!

# SSR:
SSR <- sum(resids^2)

# degrees of freedom:
dfs <- n - ncol(X)

# estimated variance of residuals:
sigma2hat <- SSR / dfs

# estimated covariance matrix of betahat:
covhatbetahat <- sigma2hat * tmp

# check for equality:
vcov(mylm)
covhatbetahat # sweet!

# estimated correlation matrix of betahat:
cov2cor(covhatbetahat)

# find standard errors:
ses <- sqrt(diag(covhatbetahat))

# check for equality:
coef(summary(mylm))[, "Std. Error"]
ses # perfect.

# t stats:
tstats <- betahat / ses

# check for equality:
coef(summary(mylm))[, "t value"]
tstats # looks good!

# p-values for testing whether beta = 0 (two sided)
pvalnorm <- 2 * pnorm(abs(tstats), lower.tail = FALSE)        # using the normal distribution
pvalt    <- 2 * pt(abs(tstats), lower.tail = FALSE, df = dfs) # using the t distribution

# check for equality:
coef(summary(mylm))[, "Pr(>|t|)"]
pvalt # that's it, that's all.
